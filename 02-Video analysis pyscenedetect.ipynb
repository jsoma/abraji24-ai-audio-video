{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b48c6ce",
   "metadata": {},
   "source": [
    "## Download the video\n",
    "\n",
    "We're going to use [yt-dlp](https://github.com/yt-dlp/yt-dlp) to download a video. It's not very fun to use so I recommend taking any troubles/questions to ChatGPT. It's a pretty popular piece of software so ChatGPT usually has good answers.\n",
    "\n",
    "First we'll install it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bda0b95-64b3-4d2d-9a8b-9dca567c900e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --quiet --upgrade \"yt-dlp[default]\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d3f9f3",
   "metadata": {},
   "source": [
    "...then we'll use it to download [this video](https://www.youtube.com/shorts/rDXubdQdJYs). If you want a different video, you just change the URL inside of the quotes. It also works for TikTok!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3efb69c-0f99-4874-a842-3dcc8e33e6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!yt-dlp \"https://www.youtube.com/shorts/rDXubdQdJYs\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1a615a",
   "metadata": {},
   "source": [
    "## Split the scenes\n",
    "\n",
    "Our question this time is: who got more screen time in this video, Joe Biden or Donald Trump? We're going to measure it by counting the length of scenes for Biden and the number of scenes for Trump.\n",
    "\n",
    "We're going to use [PySceneDetect](https://www.scenedetect.com/) to split our scenes.\n",
    "\n",
    "We'll first download it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2034d5-3637-4c44-8390-f87549bd9701",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet scenedetect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0e96e6",
   "metadata": {},
   "source": [
    "...then use it to split the video into separate scenes (and few other things, too!).\n",
    "\n",
    "When running the code below, pay attention to the **Merging formats into...** line from yt-dlp above. That's how you know know what filename to use! Sometimes the video is an mp4, but sometimes it's a webm or other format.\n",
    "\n",
    "When we run the command below, it will...\n",
    "\n",
    "- `detect-content` will split the scenes in a flexible way (there are other options, too)\n",
    "- `save-images` will save five images for each scene. They'll be in the `output` folder and be 300 pixels wide.\n",
    "- `export-html` will save an HTML file that we can use to see an overview of each scene\n",
    "- `list-scenes` will save a CSV file that lists each scene, along with details\n",
    "\n",
    "If you wanted to see separate video files for each scene you could also add `split-video` at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3273c10-da24-4881-bb88-42477f2170ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "!scenedetect -i \"The CNN Presidential debate in 60 seconds [rDXubdQdJYs].webm\" \\\n",
    "    detect-content \\\n",
    "    save-images --output output --width 300 --num-images 5 \\\n",
    "    export-html --image-width 300 \\\n",
    "    list-scenes --skip-cuts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3717dfe",
   "metadata": {},
   "source": [
    "## Optional: Download the images and HTML if you're on Google Colab\n",
    "\n",
    "If you're running this notebook online, maybe you want to download the output to be able to play with it.\n",
    "\n",
    "Honestly, you can also give up coding at this point! It's 100% possible to open up the image files directly and edit the CSV file in Excel, instead of doing all of the AI stuff we're about to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff717cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import files\n",
    "\n",
    "    !zip -r --quiet output.zip output\n",
    "\n",
    "    files.download(\"output.zip\")\n",
    "except:\n",
    "    print(\"Not on Google Colab! Not downloading\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ff7891",
   "metadata": {},
   "source": [
    "## Looking at one image\n",
    "\n",
    "We'll start by inspecting **a single image**. You will need to change the filename if you're using a different video than me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe2114a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q \"transformers[torch]\" pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcb8405",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "filename = \"output/The CNN Presidential debate in 60 seconds [rDXubdQdJYs]-Scene-002-04.jpg\"\n",
    "Image(filename=filename) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de145a34",
   "metadata": {},
   "source": [
    "We want to know who's in the image, but we can't use Claude or GPT – it cares too much about privacy and won't talk about people!\n",
    "\n",
    "Instead, we're lucky that [this smaller, open-source model](https://huggingface.co/openai/clip-vit-large-patch14) can do the detecting for us. You can test it out on the right-hand side of that page under **Inference API**.\n",
    "\n",
    "This model is a \"zero-shot classifier,\" which means we don't need to teach it what we're looking for, it already knows what (many) things in the world are.\n",
    "\n",
    "> There are lot of different ways of analyzing images, including:\n",
    ">\n",
    "> - **Classification:** Put this image into a category\n",
    "> - **Object detection:** Find specific objects in the image\n",
    "> - **Semantic segmentation:** See what pixels belong to what (cars, people, the sky, etc)\n",
    ">\n",
    "> You can see a few examples at [normalai.org](https://normalai.org/), but it also might be useful to look at the [Hugging Face tasks page](https://huggingface.co/tasks). You can also email me, I'm happy to chat! You can find me at [js4571@columbia.edu](mailto:js4571@columbia.edu)\n",
    "\n",
    "It's good to test our model first, because it might actually *not* understand what you want it to identify. While most models are good at things like cats and dogs and boats, our specific use case might be outside of its knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682407a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from PIL import Image\n",
    "\n",
    "image = Image.open(filename)\n",
    "\n",
    "detector = pipeline(\"zero-shot-image-classification\", model=\"openai/clip-vit-large-patch14\") \n",
    "results = detector(image, candidate_labels=[\"donald trump\", \"joe biden\"])\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def3a73c",
   "metadata": {},
   "source": [
    "According to the model, it's almost 100% certain that the image is of Joe Biden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fb1643",
   "metadata": {},
   "source": [
    "## Looking at all of the images\n",
    "\n",
    "Right now we're creating five images for each scene, `Scene-XXX-01.jpg` through `Scene-XXX-05.jpg`. I'm going to take the middle image – `Scene-XXX-03.jpg` and say it's representative of the rest of the scene.\n",
    "\n",
    "If we were doing this \"correctly\" we'd probably look at all five images and pick the most popular label.......but this is easier!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d33f0d0-f7ce-416e-9e31-e598d9ffbebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "filenames = glob.glob(\"output/*-Scene-*-03.jpg\")\n",
    "filenames.sort()\n",
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa3509b-f76f-42fe-a019-f99061fcddfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from PIL import Image\n",
    "\n",
    "answers = []\n",
    "for filename in filenames:\n",
    "    image = Image.open(filename)\n",
    "    \n",
    "    detector = pipeline(\"zero-shot-image-classification\", model=\"openai/clip-vit-large-patch14\") \n",
    "    results = detector(image, candidate_labels=[\"donald trump\", \"joe biden\"])\n",
    "    top_result = results[0]\n",
    "\n",
    "    if top_result['score'] > 0.9:\n",
    "        label = top_result['label']\n",
    "    else:\n",
    "        label = 'unknown'\n",
    "\n",
    "    answers.append({\n",
    "        'filename': filename,\n",
    "        'label': label\n",
    "    })\n",
    "\n",
    "    print(filename, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e5b026",
   "metadata": {},
   "source": [
    "## Combining our data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28a61db",
   "metadata": {},
   "source": [
    "Let's turn those answers into a **dataframe**, the Python equivalent to a CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06498820",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.options.display.max_colwidth = 200\n",
    "\n",
    "results_df = pd.DataFrame(answers)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359169f5",
   "metadata": {},
   "source": [
    "Remember when we first analyzed our video, and it gave us a CSV with information about each scene? It included start times, end times, length in seconds, etc. We can read that into a dataframe, too, and combine it with our labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4dcd6c-2da0-4e17-9505-e2827da4818f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"The CNN Presidential debate in 60 seconds [rDXubdQdJYs]-Scenes.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc4db76",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = results_df.join(df)\n",
    "merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3336a85a",
   "metadata": {},
   "source": [
    "We'll now save it to a CSV in case we want to look at it in Excel or Google Sheets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b94de07",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.to_csv(\"merged.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90485b53",
   "metadata": {},
   "source": [
    "And if we are currently on Google Colab, it might make sense to download it to our own computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47012ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import files\n",
    "\n",
    "    files.download(\"merged.csv\")\n",
    "except:\n",
    "    print(\"Not on Google Colab! Not downloading\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f84dc4a",
   "metadata": {},
   "source": [
    "# Do our final analysis\n",
    "\n",
    "Now let's finally get an answer to the question: who got more screen time, Joe Biden or Donald Trump?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5525647",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.groupby('label')['Length (seconds)'].sum().reset_index()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
